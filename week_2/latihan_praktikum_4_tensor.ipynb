{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2NbAb+OB6q5zuUGvc7FaL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimasnurmiraj/221230053-Pengantar-ML/blob/main/week_2/latihan_praktikum_4_tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5q_NqcPAFFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60341a63-69c2-498b-f9a6-a0c6f713970b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== LINEAR LAYER OUTPUT (first 5 rows) ===\n",
            " tensor([[-2.0634],\n",
            "        [-2.0481],\n",
            "        [-8.9384],\n",
            "        [ 4.7898],\n",
            "        [-4.7585]])\n",
            "\n",
            "=== RELU ACTIVATION (first 5 rows) ===\n",
            " tensor([[0.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [4.7898],\n",
            "        [0.0000]])\n",
            "\n",
            "=== BATCH NORMALIZATION (first 5 rows) ===\n",
            " tensor([[ 0.1607, -0.0610, -0.2393, -0.8636,  0.1858,  0.5207, -0.0631, -0.1313,\n",
            "          1.6012, -0.7617],\n",
            "        [ 0.5567, -1.1333,  0.2830,  2.0541,  0.3319,  0.1168,  0.0771, -0.8561,\n",
            "          0.4582,  1.1926],\n",
            "        [ 1.5247,  1.2261,  1.4682, -0.4088,  0.3330, -1.7847,  1.1030, -1.0003,\n",
            "         -0.7506,  0.6441],\n",
            "        [-0.9019, -2.3782, -1.3440,  0.0370, -2.2845,  0.9254, -0.2291, -0.7587,\n",
            "          0.0550, -0.6637],\n",
            "        [ 0.7565,  1.4464,  0.7666, -0.3789, -0.0633, -0.2577,  0.4145, -0.3639,\n",
            "          1.7352,  1.8449]])\n",
            "\n",
            "=== LABELS ===\n",
            " tensor([0, 0, 3, 3, 1, 3, 3, 0])\n",
            "\n",
            "=== ONE-HOT ENCODING ===\n",
            " tensor([[1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [1., 0., 0., 0.]])\n",
            "\n",
            "=== MATRIX MULTIPLICATION TEST ===\n",
            "Manual result:\n",
            " tensor([[ 6.,  2.],\n",
            "        [ 3., -1.]])\n",
            "Torch result:\n",
            " tensor([[ 6.,  2.],\n",
            "        [ 3., -1.]])\n",
            "\n",
            "✅ Semua test lulus tanpa error!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ==================================================\n",
        "# Simulasi batch data (32 sampel, 10 fitur)\n",
        "# ==================================================\n",
        "batch_size, n_features = 32, 10\n",
        "torch.manual_seed(123)  # seed agar hasil reproducible\n",
        "X = torch.randn(batch_size, n_features)\n",
        "W = torch.randn(n_features, 1)\n",
        "b = torch.randn(1)\n",
        "\n",
        "# ==================================================\n",
        "# Linear layer (y = XW + b)\n",
        "# ==================================================\n",
        "def linear_layer(x, w, bias):\n",
        "    return x @ w + bias\n",
        "\n",
        "y_linear = linear_layer(X, W, b)\n",
        "\n",
        "# ==================================================\n",
        "# ReLU Activation\n",
        "# ==================================================\n",
        "def relu(x):\n",
        "    return torch.clamp(x, min=0.0)  # lebih ringkas pakai clamp\n",
        "\n",
        "y_relu = relu(y_linear)\n",
        "\n",
        "# ==================================================\n",
        "# Batch Normalization sederhana\n",
        "# ==================================================\n",
        "def batch_norm(x, eps=1e-5):\n",
        "    mean = x.mean(dim=0, keepdim=True)\n",
        "    std = x.std(dim=0, unbiased=False, keepdim=True)  # pakai unbiased=False biar stabil\n",
        "    return (x - mean) / (std + eps)\n",
        "\n",
        "y_bn = batch_norm(X)\n",
        "\n",
        "# ==================================================\n",
        "# One-hot Encoding\n",
        "# ==================================================\n",
        "def one_hot_encoding(labels, num_classes):\n",
        "    oh = torch.zeros(labels.size(0), num_classes)\n",
        "    oh[torch.arange(labels.size(0)), labels] = 1\n",
        "    return oh\n",
        "\n",
        "labels = torch.randint(0, 4, (8,))  # modifikasi: kelas jadi 4, label 8 sampel\n",
        "y_onehot = one_hot_encoding(labels, num_classes=4)\n",
        "\n",
        "# ==================================================\n",
        "# Manual Matrix Multiplication\n",
        "# ==================================================\n",
        "def manual_matmul(A, B):\n",
        "    m, n = A.shape\n",
        "    n2, p = B.shape\n",
        "    assert n == n2, \"Inner dimensions must match\"\n",
        "    C = torch.zeros(m, p)\n",
        "    for i in range(m):\n",
        "        for j in range(p):\n",
        "            C[i, j] = torch.sum(A[i, :] * B[:, j])  # lebih ringkas\n",
        "    return C\n",
        "\n",
        "# Uji coba\n",
        "A = torch.tensor([[2., 0.], [1., -1.]], dtype=torch.float32)\n",
        "B = torch.tensor([[3., 1.], [0., 2.]], dtype=torch.float32)\n",
        "manual_res = manual_matmul(A, B)\n",
        "torch_res = A @ B\n",
        "\n",
        "# ==================================================\n",
        "# OUTPUT\n",
        "# ==================================================\n",
        "print(\"=== LINEAR LAYER OUTPUT (first 5 rows) ===\\n\", y_linear[:5])\n",
        "print(\"\\n=== RELU ACTIVATION (first 5 rows) ===\\n\", y_relu[:5])\n",
        "print(\"\\n=== BATCH NORMALIZATION (first 5 rows) ===\\n\", y_bn[:5])\n",
        "print(\"\\n=== LABELS ===\\n\", labels)\n",
        "print(\"\\n=== ONE-HOT ENCODING ===\\n\", y_onehot)\n",
        "\n",
        "print(\"\\n=== MATRIX MULTIPLICATION TEST ===\")\n",
        "print(\"Manual result:\\n\", manual_res)\n",
        "print(\"Torch result:\\n\", torch_res)\n",
        "\n",
        "# ==================================================\n",
        "# Assertions\n",
        "# ==================================================\n",
        "assert y_linear.shape == (batch_size, 1), \"Linear output salah\"\n",
        "assert torch.all(y_relu >= 0), \"ReLU salah (ada nilai negatif)\"\n",
        "assert y_bn.shape == X.shape, \"Batch norm shape salah\"\n",
        "assert y_onehot.shape == (8, 4), \"One-hot shape salah\"\n",
        "assert torch.allclose(manual_res, torch_res), \"Matrix multiplication salah\"\n",
        "\n",
        "print(\"\\n✅ Semua test lulus tanpa error!\")\n"
      ]
    }
  ]
}